{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b105c3a0-5131-4d32-b77c-dd6611d37c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9056c409-990d-4471-8e2d-e9e03d7e60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ccff3f-b8f9-409a-a1b8-6b41d3557cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/transcript_chunk.csv', sep=',')\n",
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebfa7d63-1444-4e21-aee5-7eae5f9cb3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a user of our YouTube assistant application.\n",
    "Formulate 5 questions this user might ask based on a provided transcript chunk.\n",
    "Make the questions specific to this transcript chunk.\n",
    "The record should contain the answers to the questions, and the questions should\n",
    "be complete and not too short. Use as few words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "subtitle: {subtitle}\n",
    "text_chunk: {text_chunk}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "{{\"questions\": [\"question1\", \"question2\", ..., \"question5\"]}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82817428-a175-417e-9681-1b269f5cafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(**documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663a8293-cf23-40fb-85d5-926586798dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827de8bb-011c-4b4e-bd15-9450465096d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e328b6-4fa3-42c6-a179-3c98b0819b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e9cbdb2-374d-4b4e-9079-d0e38ffc88bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['What is the purpose of the office hours session mentioned in the transcript?',\n",
       "  'How many people joined the office hours according to the transcript?',\n",
       "  \"Who asked the question about the video's content during the session?\",\n",
       "  'Is this the first office hours session held, based on the transcript?',\n",
       "  'What is the general tone of the speaker in the introduction?']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66748cd9-208f-4ad1-8527-d0832adc758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279ba517-9d73-4be6-9b39-77bdcc30cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ca246f8-343d-479b-8958-566e17e6cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb436cd-3c19-4971-9c9d-13f7ca961075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae9bd6a492e45d0b11eb70902a2d97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents): \n",
    "    doc_id = doc['chunk_id']\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions_raw = generate_questions(doc)\n",
    "    questions = json.loads(questions_raw)\n",
    "    results[doc_id] = questions['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daf003f1-44e5-44b1-8679-e0bb4fa1d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "\n",
    "\n",
    "for doc_id, questions in results.items():\n",
    "    for q in questions:\n",
    "        final_results.append((doc_id,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620b0fe6-ba71-44d4-9a03-4b78a212225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(final_results, columns=['id', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b39b105-e816-4b0f-bc41-6c4439d287f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('../data/ground-truth-retrieval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c4ebcd-bdaa-4d64-b02d-08c149a4908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,question\n",
      "0,What is the purpose of the office hours session mentioned in the transcript?\n",
      "0,How many people have joined the office hours?\n",
      "0,Who asked the first question during the office hours?\n",
      "0,How long has it been since the last office hours session?\n",
      "0,What greeting does the host use to welcome participants?\n",
      "1,What specific topics will this video cover?\n",
      "1,\"Is it only about projects, or can we ask other questions too?\"\n",
      "1,Who asked the initial question in the video?\n",
      "1,What is the main purpose of this video?\n"
     ]
    }
   ],
   "source": [
    "!head ../data/ground-truth-retrieval.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322f7fb-29d3-4184-a124-fef2d373f0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pipenv)",
   "language": "python",
   "name": "youtube-chat-companion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
