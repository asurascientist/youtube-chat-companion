{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2c537-d169-418f-8921-808a935c5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0130ae3-8d33-4b01-af14-ee4c1f86a33f",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c9b801-b09c-467f-9e93-5e499b2f4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "import minsearch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f259bd-65a3-4888-ad02-af830f4a2bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe9117e-0389-49f4-be65-d2fb45986541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transcript(video_id):\n",
    "    try:\n",
    "        # Check available transcripts for the video\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        transcript = transcript_list.find_transcript([t.language_code for t in transcript_list])\n",
    "        \n",
    "        language_code = transcript.language_code\n",
    "        language = transcript.language\n",
    "\n",
    "        print(f\"Pulling transcript for video {video_id} in {language}\")\n",
    "        # Fetch the transcript text\n",
    "        fetched_transcript = transcript.fetch()\n",
    "        \n",
    "    except TranscriptsDisabled:\n",
    "        return \"Subtitles are disabled for this video.\"\n",
    "    except NoTranscriptFound:\n",
    "        return \"No transcript available in any language.\"\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "    metadata = {\n",
    "        \"language_code\": language_code,\n",
    "        \"language\": language,\n",
    "        \"generated\": True\n",
    "\n",
    "    }\n",
    "    return fetched_transcript, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f82cff0-eb66-4c9e-a1fc-d49cd9110511",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_transcript_prompt = '''\n",
    "You are a professional editor with expertise in data science. Transform the following podcast transcript into clear, readable text while preserving all original information.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Include All Content: Ensure the entire transcript content appears in the final output. Do not omit any key parts.\n",
    "2. Remove Filler Words and Sounds: Eliminate filler words like \"so,\" \"right,\" \"like\" when they add no value. Remove any hums, \"mhms,\" or similar sounds.\n",
    "3. Enhance Sentence Clarity: Rephrase sentences for clarity and grammatical correctness:\n",
    "- Avoid starting sentences with conjunctions like \"And.\"\n",
    "- Reframe any sentences that end with \"right\" into questions if possible.\n",
    "4. Structure in Paragraphs: Use a clear paragraph structure:\n",
    "- Logical Breaks: Begin a new paragraph at the end of each thought to enhance readability.\n",
    "- Paragraph Length: Limit paragraphs to 5-6 sentences for better flow.\n",
    "5. Major Topic Shifts: For noticeable shifts in topic, insert a separator ~~ between blocks of paragraphs.\n",
    "6. Subtitles and Conclusion:\n",
    "- Subtitles: Start each major section with a subtitle summarizing the main topic.\n",
    "- Conclusion: Add a \"Conclusion\" subtitle summarizing key points from all sections, not just the final one. Ensure the summary covers main ideas and themes across the transcript.\n",
    "\n",
    "Output format : \n",
    "[\n",
    "    {{\n",
    "        \"subtitle\": \"<subtitle>\",\n",
    "        \"text\": \"Sentence 1 of paragraph 1. Sentence 2 of paragraph 1. Sentence 3 of paragraph 1...\"\n",
    "    }},\n",
    "    {{\n",
    "        \"subtitle\": \"<subtitle>\",\n",
    "        \"text\": \"Sentence 1 of paragraph 1. Sentence 2 of paragraph 1. Sentence 3 of paragraph 1...\"\n",
    "    }},\n",
    "    ........\n",
    "    {{\n",
    "        \"subtitle\": \"<Conclusion>\",\n",
    "        \"text\": \"A comprehensive summary capturing the main ideas, what is the video about, and themes discussed across all sections.\"\n",
    "\n",
    "    }}\n",
    "]\n",
    "transcript:\n",
    "{transcript}\n",
    "'''\n",
    "\n",
    "def get_clean_transcript_json_formated(transcript, model='gpt-4o-mini'):\n",
    "    transcript_chunk = [chunk['text'] for chunk in transcript]\n",
    "    prompt = clean_transcript_prompt.format(transcript=transcript_chunk)\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages=[{\"role\":\"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dedab13-e2e8-47ba-a05e-ec1269870ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Directory to save individual transcript files\n",
    "TRANSCRIPTS_DIR = \"../data/transcripts/\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(TRANSCRIPTS_DIR, exist_ok=True)\n",
    "\n",
    "# Helper function to construct the unique file path for a video transcript\n",
    "def get_transcript_file_path(video_id):\n",
    "    filename = f\"{video_id}.csv\"\n",
    "    return os.path.join(TRANSCRIPTS_DIR, filename)\n",
    "\n",
    "def sanitize_video_id(video_id):\n",
    "    \"\"\"Convert hyphens in video ID to underscores for file compatibility.\"\"\"\n",
    "    return video_id.replace('-', '_')\n",
    "\n",
    "# Function to check if a transcript file exists for the specified video\n",
    "def check_existing_transcript(video_id):\n",
    "    file_path = get_transcript_file_path(video_id)\n",
    "    \n",
    "    # Check if the file exists, and if so, return the content as a list of dictionaries\n",
    "    if os.path.exists(file_path):\n",
    "        return pd.read_csv(file_path).to_dict(orient='records')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to save transcript chunks to a uniquely named CSV file\n",
    "def save_transcript_chunks(video_id, chunks):\n",
    "    file_path = get_transcript_file_path(video_id)\n",
    "    chunks_df = pd.DataFrame(chunks)\n",
    "    chunks_df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4895c617-60f9-4be7-aa1f-34096efb1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chunked_transcript(video_id, max_chunk_length=250, overlap_length=50, min_chunk_length=100):\n",
    "    \n",
    "    # Check if the file already exists based on actual language metadata\n",
    "    existing_transcript = check_existing_transcript(video_id)\n",
    "    if existing_transcript:\n",
    "        metadata = {\n",
    "            \"language_code\": existing_transcript[0]['language_code'],\n",
    "            \"language\": existing_transcript[0]['language'],\n",
    "            \"generated\": False\n",
    "        }\n",
    "        print(f\"Transcript already generated for video ID.\")\n",
    "        return existing_transcript, metadata\n",
    "\n",
    "    # Generate transcript only if it does not already exist\n",
    "    raw_transcript, metadata = generate_transcript(video_id)\n",
    "    if isinstance(raw_transcript, str):  # If the transcript generation returns an error message, return it\n",
    "        return raw_transcript\n",
    "    \n",
    "    # Generate clean transcript\n",
    "    clean_transcript = get_clean_transcript_json_formated(raw_transcript)\n",
    "    transcript = json.loads(clean_transcript)\n",
    "    # Split the transcript into chunks\n",
    "    \n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "\n",
    "    for section in transcript:\n",
    "        subtitle = section.get(\"subtitle\", \"\")\n",
    "        text = section.get(\"text\", \"\").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "        words = text.split(\" \")\n",
    "        current_chunk = \"\"\n",
    "\n",
    "        for word in words:\n",
    "            if len(current_chunk) + len(word) + 1 > max_chunk_length:\n",
    "                if current_chunk and len(current_chunk) >= min_chunk_length:\n",
    "                    overlap_words = current_chunk.split()[-(overlap_length // 5):]\n",
    "                    overlap_part = \" \".join(overlap_words)\n",
    "                    chunks.append({\n",
    "                        \"video_id\": sanitize_video_id(video_id),\n",
    "                        \"language_code\": metadata['language_code'],\n",
    "                        \"language\": metadata['language'],                        \n",
    "                        \"subtitle\": subtitle,\n",
    "                        \"chunk_id\": chunk_id,\n",
    "                        \"text_chunk\": current_chunk.strip()\n",
    "                    })\n",
    "                    chunk_id += 1\n",
    "                    current_chunk = overlap_part + \" \" + word\n",
    "                else:\n",
    "                    current_chunk += \" \" + word\n",
    "            else:\n",
    "                current_chunk += \" \" + word\n",
    "\n",
    "        if current_chunk.strip():\n",
    "            chunks.append({\n",
    "                \"video_id\": sanitize_video_id(video_id),\n",
    "                \"language_code\": metadata['language_code'],\n",
    "                \"language\": metadata['language'],                        \n",
    "                \"subtitle\": subtitle,\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"text_chunk\": current_chunk.strip()\n",
    "            })\n",
    "            chunk_id += 1\n",
    "    \n",
    "    # Save chunks to file using actual `original_language`\n",
    "    save_transcript_chunks(video_id, chunks)\n",
    "    print(f\"Transcript generated successfully for video ID {video_id}.\")\n",
    "\n",
    "    \n",
    "    return chunks, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37eb202f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript already generated for video ID.\n"
     ]
    }
   ],
   "source": [
    "chunked_transcript,metadata = generate_chunked_transcript('L2GKmEH-gdg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b114bbe3-f7c5-4280-a0c7-d7322c4aa2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'language_code': 'id',\n",
       " 'language': 'Indonesian (auto-generated)',\n",
       " 'generated': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867833b3-399d-4b67-87c2-182c0a1fc202",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bb9f059-ee02-4e7a-b67b-02119eff595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "\n",
    "def initialize_and_load_index(chunked_transcript=None):\n",
    "    \"\"\"\n",
    "    Initializes the global index if it is not already an instance of the Index class, and load it if it is already initialized\n",
    "    \n",
    "    Returns:\n",
    "        Index: An instance of the Index class.\n",
    "    \"\"\"\n",
    "    global index\n",
    "    #initialize index if not initialize\n",
    "    if not isinstance(index, minsearch.Index):\n",
    "        index = minsearch.Index(\n",
    "            text_fields=['subtitle', 'text_chunk'],\n",
    "            keyword_fields=['video_id', 'chunk_id', 'language_code', 'language']\n",
    "        )\n",
    "        if chunked_transcript is not None:\n",
    "            video_id = chunked_transcript[0]['video_id']\n",
    "            index.fit(chunked_transcript)\n",
    "            print(f\"{video_id} are indexed successfully.\")\n",
    "\n",
    "    else:\n",
    "        if chunked_transcript is not None:\n",
    "            video_id = chunked_transcript[0]['video_id']\n",
    "            index.fit(chunked_transcript)\n",
    "            print(f\"{video_id} are indexed successfully.\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c0af8af-d92a-4361-a71b-18e425e61da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2GKmEH_gdg are indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "index = initialize_and_load_index(chunked_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2442238e-fa84-4537-9fe4-f5d74d3986bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query,video_id):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={\"video_id\": sanitize_video_id(video_id)},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20cd4dcd-47c4-4c04-9a6a-e81ec533a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'video_id': 'L2GKmEH_gdg',\n",
       "  'language_code': 'id',\n",
       "  'language': 'Indonesian (auto-generated)',\n",
       "  'subtitle': 'Keterpurukan di Liga Champions',\n",
       "  'chunk_id': 11,\n",
       "  'text_chunk': 'fans geram, dan pemain berusia 25 tahun ini disebut sebagai faktor utama kekalahan tim. Kritikan juga menyebut Mbappé sebagai pemain yang malas karena kurang berkontribusi saat bertahan.'},\n",
       " {'video_id': 'L2GKmEH_gdg',\n",
       "  'language_code': 'id',\n",
       "  'language': 'Indonesian (auto-generated)',\n",
       "  'subtitle': 'Kekalahan Melawan AC Milan',\n",
       "  'chunk_id': 13,\n",
       "  'text_chunk': 'setelah mencetak gol. Hasil negatif ini memperpanjang rekor buruk Los Blancos di Liga Champions. Performanya yang kurang baik membuat Real Madrid semakin kesulitan untuk mempertahankan gelar, meskipun mereka diprediksi sebagai salah satu unggulan'},\n",
       " {'video_id': 'L2GKmEH_gdg',\n",
       "  'language_code': 'id',\n",
       "  'language': 'Indonesian (auto-generated)',\n",
       "  'subtitle': 'Kritik terhadap Mbappé',\n",
       "  'chunk_id': 4,\n",
       "  'text_chunk': 'setiap gelar musim ini. Namun, kedatangannya mendapatkan penolakan dari berbagai pihak. Salah satunya, Pedro Mijatovic, yang mengkritik kehadiran Mbappé karena dianggap bisa merusak suasana kondusif di ruang ganti. Real Madrid memiliki enam pemain'},\n",
       " {'video_id': 'L2GKmEH_gdg',\n",
       "  'language_code': 'id',\n",
       "  'language': 'Indonesian (auto-generated)',\n",
       "  'subtitle': 'Kritik terhadap Mbappé',\n",
       "  'chunk_id': 3,\n",
       "  'text_chunk': 'Kedatangan Mbappé sempat mengguncang publik sepak bola dunia. Dia dianggap akan menjadi pemain sukses di Real Madrid dan bahkan siap membawa tim tersebut memenangkan setiap gelar musim ini. Namun, kedatangannya mendapatkan penolakan dari berbagai'},\n",
       " {'video_id': 'L2GKmEH_gdg',\n",
       "  'language_code': 'id',\n",
       "  'language': 'Indonesian (auto-generated)',\n",
       "  'subtitle': 'Kedatangan Kylian Mbappé di Real Madrid',\n",
       "  'chunk_id': 0,\n",
       "  'text_chunk': 'Kylian Mbappé kembali menjadi sorotan karena gagal memberikan kontribusi besar. Mega bintang ini tidak berhasil mencetak gol dalam dua laga terakhir menghadapi Barcelona dan AC Milan. Selain itu, kehadiran Mbappé dinilai menghambat performa bintang'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"video ini tentang apa?\", \"L2GKmEH-gdg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "46737962-a030-45db-b6cf-8365c443a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a video assistant. Answer the QUESTION based on the CONTEXT from our YouTube transcript chunks.\n",
    "- If the QUESTION and CONTEXT are in different languages, translate the QUESTION to match the CONTEXT language before answering.\n",
    "- Use only the information from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "subtitle: {subtitle}\n",
    "text_chunk: {text_chunk}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, transcript_chunks):\n",
    "    context = \"\"\n",
    "    \n",
    "    for chunk in transcript_chunks:\n",
    "        context += entry_template.format(**chunk) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7be272c5-2e04-4479-ab64-9a7284c8fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages=[{\"role\":\"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "009b5795-f4db-483e-a025-7e16b6f15610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "948e92e9-81cd-4eac-911c-b1131b44d8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silakan berikan potongan transkrip dari video tersebut agar saya dapat membantu menjawab pertanyaan tentang isi video ini.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'video ini tentang apa?'\n",
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc4b4e46-7ccd-404e-8f0f-6d53600f40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(chunked_transcript)\n",
    "\n",
    "df.to_csv('../data/transcript_chunk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c511dd7-52ed-4e19-a18b-40e1dbc2e67f",
   "metadata": {},
   "source": [
    "## Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12273d52-741b-4cac-a5d7-6c6473b4f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv(\"../data/ground-truth-retrieval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1612da3b-46ba-4197-b0e3-e1460ba298d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the purpose of the office hours sessio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>How many people have joined the office hours?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Who asked the first question during the office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>How long has it been since the last office hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>What greeting does the host use to welcome par...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question\n",
       "0   0  What is the purpose of the office hours sessio...\n",
       "1   0      How many people have joined the office hours?\n",
       "2   0  Who asked the first question during the office...\n",
       "3   0  How long has it been since the last office hou...\n",
       "4   0  What greeting does the host use to welcome par..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "897c0776-a9d0-4e23-96bf-ccd83f42a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8799e490-fd5e-4292-99b5-c96adc252cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3f99708-3e8c-454f-8086-79bc2ae0e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72c05316-794e-4678-994a-6408f886fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "    \n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['chunk_id']== doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9f5f742d-ea07-406e-a9a6-e836fdef7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352c4c86deb94adbb906aaf16d1ab7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9219512195121952, 'mrr': 0.5398993418505613}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth,lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4630d4-c262-4d06-aeee-ef615cd3dd63",
   "metadata": {},
   "source": [
    "## Finding best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e72d50d4-f3d7-460a-b29c-0d57f6295e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_question[:100]\n",
    "df_test = df_question[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d500c508-f56a-486b-a1d8-ec885d3f30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf') # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        #generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(mini_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "\n",
    "        #evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "\n",
    "        # Update best if current is better\n",
    "        if current_score > best_score: # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23c757bb-f8f4-4a98-9339-38c1f5074988",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c30c1306-c9f8-4b63-a8cd-2ae042228ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, video_id,boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={\"video_id\": video_id},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d88937b1-006e-41d1-90b6-173de610523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'subtitle': (0.0, 3.0),\n",
    "    'original_language': (0.0, 1.0),\n",
    "    'translate_language': (0.0, 1.0),\n",
    "    'chunk_text': (0.0, 3.0),\n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], 'pA9S1mTqAwU',boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f4b78d86-1d5a-4a0d-9979-889ad0d93b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d8afcf9ef84b419c1083b5223965d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b33fd0dcc047e6972480f40492bec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c320984a674e18bc725d702c9cef26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab3006505d04f1992650285a9e294ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c740862845f47129aa3972b1de84e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef7fbd3fb4a44c89a719776d047643b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20293b93339f4ce6a2ad2b60578d3ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fa3704816e41998c8941e2b3249ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37a4cc8ec26450cb42e38c2f5afe0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544d84c8345f4336b9ccee57690f4a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4bdf0ec0774a088082cf0ea15ab487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d063a077f94c24aeb6938be66d5319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c1282b93d2499c919bd67eb34534a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c925d7b6ee734ff5bf14d2cd4777af17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac40a2f4a592484da1aef8980516bc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2203ee900fda4b439b64359066ffddf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfa7318f4c149cf9414bd470451fbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68aee51d326482d93f6e8cb5468104a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12b9714b84a416fbf5c75d1a491ce64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4b157176ed4a88a4ea1e21f1549c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'subtitle': 0.14229395552278223,\n",
       "  'original_language': 0.69032315975889,\n",
       "  'translate_language': 0.05899131672045521,\n",
       "  'chunk_text': 0.9115689008437606},\n",
       " 0.8157301587301587)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3dbc676a-3c94-457b-a88c-7fedccd1f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "        'subtitle': 0.14229395552278223,\n",
    "        'original_language': 0.69032315975889,\n",
    "        'translate_language': 0.05899131672045521,\n",
    "        'chunk_text': 0.9115689008437606\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        num_results=10\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0713f58-ee6f-4c9c-bf6e-a16dec9ebd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f515073eb55f457b88ff6a1923dd690c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9219512195121952, 'mrr': 0.5398993418505613}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b0ab6b-db1e-4632-ac21-7de50ee0afa7",
   "metadata": {},
   "source": [
    "## RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2670e1df-71bf-4b1e-b5ee-e2350a1c7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40d8037d-2abc-4e53-943c-2a4820dd7fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71327811-da45-458f-b11e-86bde377efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "04cadefd-e62e-410e-994a-d42ca2674229",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = rag(record['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c0820ab5-eb53-404d-92bf-e4f0c3b05f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El propósito de la sesión de horas de oficina mencionada en la transcripción es responder a las preguntas de los estudiantes, especialmente sobre los proyectos, aunque también se les invita a hacer preguntas que no estén directamente relacionadas con los proyectos.\n"
     ]
    }
   ],
   "source": [
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a10ea22b-c288-4b56-a931-84eb61cf1a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: What is the purpose of the office hours session mentioned in the transcript?\n",
      "Generated Answer: El propósito de la sesión de horas de oficina mencionada en la transcripción es responder a las preguntas de los estudiantes, especialmente sobre los proyectos, aunque también se les invita a hacer preguntas que no estén directamente relacionadas con los proyectos.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=record['question'], answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9153cd64-401e-4c03-93cc-ad047b0cd9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e666eb34-b60e-473b-a006-24603eaa14a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "92e56e70-8a45-449f-a3e2-1a83eaa31c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = minsearch_improved(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "266c0ac7-8a71-4f73-a824-292dcc2d0dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8034bf766bce4918ae0bbed63a054a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question)\n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c76a682-38ec-42ad-a050-8293fc3a4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f18dcc31-c717-443d-8b81-b9917071a756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.85\n",
       "PARTLY_RELEVANT    0.14\n",
       "NON_RELEVANT       0.01\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e5a29718-58c2-4aa9-8bdb-d8e18e116c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/rag-eval-gpt-4o-mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7d658231-83e7-46c9-b394-11412aa88a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The notable differences in evaluation criteria...</td>\n",
       "      <td>8</td>\n",
       "      <td>What are the notable differences in evaluation...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer hints at the existence of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The purpose of the pinned link in the chat is ...</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the purpose of the pinned link in the ...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer touches on the purpose of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A common issue with YouTube video transcripts ...</td>\n",
       "      <td>17</td>\n",
       "      <td>What is a common issue with YouTube video tran...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer identifies an issue relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Different metrics can be utilized to assess pe...</td>\n",
       "      <td>23</td>\n",
       "      <td>What types of metrics can be used for assessment?</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer discusses metrics related...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Project deliverables are crucial as they ensur...</td>\n",
       "      <td>31</td>\n",
       "      <td>Can you explain the importance of project deli...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer discusses the importance of project...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               answer  id  \\\n",
       "3   The notable differences in evaluation criteria...   8   \n",
       "7   The purpose of the pinned link in the chat is ...   3   \n",
       "14  A common issue with YouTube video transcripts ...  17   \n",
       "16  Different metrics can be utilized to assess pe...  23   \n",
       "19  Project deliverables are crucial as they ensur...  31   \n",
       "\n",
       "                                             question        relevance  \\\n",
       "3   What are the notable differences in evaluation...  PARTLY_RELEVANT   \n",
       "7   What is the purpose of the pinned link in the ...  PARTLY_RELEVANT   \n",
       "14  What is a common issue with YouTube video tran...  PARTLY_RELEVANT   \n",
       "16  What types of metrics can be used for assessment?  PARTLY_RELEVANT   \n",
       "19  Can you explain the importance of project deli...  PARTLY_RELEVANT   \n",
       "\n",
       "                                          explanation  \n",
       "3   The generated answer hints at the existence of...  \n",
       "7   The generated answer touches on the purpose of...  \n",
       "14  The generated answer identifies an issue relat...  \n",
       "16  The generated answer discusses metrics related...  \n",
       "19  The answer discusses the importance of project...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval.relevance == 'PARTLY_RELEVANT'][:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pipenv)",
   "language": "python",
   "name": "youtube-chat-companion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
